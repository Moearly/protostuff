#summary Best practices, tradeoffs, techniques
#labels Featured

= Things you need to know =

== Serialization Formats ==

When choosing a format, you need to know the limitations and tradeoffs each format brings.

===={{{protobuf}}}====
messages cannot be streamed (comes with its internal format)

 * what the official protobuf java implementation does:
   * it computes the size of each message and stores it on a private int field named "memoizedSerializedSize".  
   * this means when your message contains a lot of nested messages, it will traverse every message (iterates the list if repeated field) on the graph (to compute the total size of the root message) before it can perform any serialization.
   * the good thing about it is, it can perform validation on each message's fields (while computing the size) before the message is actually written (w/c is the proper way to do so).
   * Tradeoffs:
     * None.  Protobuf was designed to have validation from the get-go, therefore, you cannot be streaming messages anyway.

 * what protobuf/protostuff does:
   * same applies, cannot be streamed (comes with the format)
   * validation and message size computation needs to happen during serialization (3-in-1 setting)
     * But wait, isn't it a bad idea to perform serialization when the message itself has not yet been declared valid?  
       * Yes.
     * Does it mean I could be partially writing to the socket ({{{OutputStream}}}) when the {{{UnintializedMessageException}}} (required field missing) is thrown?
       * No.  We are buffering the writes to a series of logical buffers (one physical byte array if message size <= byte array size)
       * This means that the message needs to be fully computed and validated (while serializing to a byte array) before it can be written to the socket ({{{OutputStream}}}).
     * Tradeoffs
       * Even if you don't require validation, you still need to fully buffer the messages to reduce the serialization step to 1 instead of 2 (w/c is normally: 1. traverse the graph for validation/computation and 2.  traverse the graph again for the actual serialization)

===={{{protostuff}}}====
messages can be streamed like most serialization formats (e.g json)

If you need validation, then you need to buffer your writes before writing to the socket ({{{OutputStream}}}).
  {{{
     LinkedBuffer buffer = ...;
     try
     {
       int size = ProtostuffIOUtil.writeTo(buffer, message, schema);
       // you can prefix the message with the size (delimited message)
       LinkedBuffer.writeTo(outputStream, buffer);
     }
     catch(UninitializedMessageException e)
     {
       // your message was not written to the stream
       // because it was missing required fields.
     }
     finally
     {
       buffer.clear();
     }
     
  }}}

validation is built-in on the schema api but that does not mean you have to use it.
  * If messages are generated from .proto, simply avoid using "required" on any of your fields.
  * If using the runtime schemas, everything is "optional" (or "repeated" for collections).

when serializing utf8 strings, protostuff tries to do 2 things at once by writing to the buffer and computing the size at the same time.
  * Why? Computation is required since a protobuf string requires that it's length be written first before the actual value.
  * How? The max size of a utf8 string can be computed and protostuff uses that to decide how to efficiently perform the serialization.
  * In streaming mode (directly writing to socket {{{OutputStream}}}), if the utf8 string size is too large to fit in the initial buffer({{{LinkedBuffer.allocate(size)}}}), protostuff will create session buffers.
    * What are session buffers?
      * These are small incremental buffers that are created, cached and  re-used while writing to the {{{OutputStream}}}.
      * These buffers are flushed to the stream immediately after a complete utf8 string write (2-in-1: buffer write + utf8 size computation).
  * See the source code for protostuff-api ({{{StreamedStringSerializer}}}) for more details.

Tradeoffs:
  * protostuff does a lot of atomic operations for speed in exchange for internal buffering (on streaming mode) when needed.
  * this tradeoff arguably makes protostuff the [http://code.google.com/p/thrift-protobuf-compare/wiki/BenchmarkingV2 fastest java serializer] on serialization mode.

===={{{graph}}}====

Use it if you're serializing object graphs with cyclic references.

Same tradeoffs with protostuff plus a small overhead of using an {{{IdentityHashMap}}} to identify cyclic references.

===={{{json}}}====

No tradeoffs.  Use it if you're talking to a browser.

===={{{xml}}}====

Not as fast as the other formats but could be useful for legacy comms.

===={{{yaml}}}====

If you want to visualize the messages coming from your services/server, you'll want to use this.

==Serializing object graphs==

It is not portable to all the formats supported.

The graph/reference logic is embedded in the serialization format (protostuff) to achieve high performance graph ser/deser.

When you serialize the root object, its nested messages should not have a reference to it.  See [SerializingObjectGraphs] for more details.

==Polymorphic serialization==

This is only available for protostuff-runtime (obviously).

What does this really mean?
 * A pojo can have a field that is not a concrete type.
 * E.g 
{{{
   public interface Foo
   {
       // ...
   }
   public abstract class Bar
   {
       // ...
   }
   public final class Person
   {
       Foo foo;
       Bar bar;
       Object baz; // can be foo or bar
   } 
}}}

==Runtime Options==

Runtime options for protostuff-runtime:
 * -Dprotostuff.runtime.enums_by_name=true
   * Your enums are serialized using the string from Enum.name();
   * By default, this is disabled for protobuf compatibility (enums serialized using their number)
 * -Dprotostuff.runtime.collection_schema_on_repeated_fields=true
   * The collection (repeated field) will be serialized like a regular message (even if the collection is empty).
   * Disabled by default for protobuf compatibility (the collection is not serialized, only its values).
   * Here's an example (read the comments):
{{{
public final class Foo
{
   List<String> stringList;

   // equals and hashCode methods

}
}}}
   * Ser/deser
{{{
   LinkedBuffer buffer = ...;
   Foo foo = new Foo();
   // empty list
   foo.stringList = new ArrayList<String>();

   final byte[] data;
   try
   {
       data = ProtostuffIOUtil.toByteArray(foo, schema, buffer);
   }
   finally
   {
       buffer.clear();
   }

   Foo f = new Foo();
   
   ProtostuffIOUtil.mergeFrom(data, f, schema);
   
   assertEquals(f, foo); // this will fail if the option is not enabled because f.stringList will be null.
   // It would have been an empty list if the option was enabled (w/c makes it equal)
   
}}}

 * -Dprotostuff.runtime.auto_load_polymorphic_classes=false
   * Polymorphic serialization includes the concrete type of the object being serialized.  Upon deserialization, that className is read and is used to fetch the derived schema.
{{{
    boolean autoLoad = RuntimeSchema.AUTO_LOAD_POLYMORHIC_CLASSES;
    String className = ...; // read from the input.
    Schema<Object> derivedSchema = RuntimeSchema.getSchema(className, autoLoad);
    // If the class has not been loaded, and autoLoad is true, it will be loaded from the context classloader.
    // If autoLoad is false, a ProtostuffException is thrown (illegal operation, unknown message)
}}}
   * Enabled by default.  For security purposes, you can pre-load all your known pojos and disable this. Here's how:
{{{
// the code below preloads the schema of your pojos.
RuntimeSchema.getSchema(SomePojo.class);
RuntimeSchema.getSchema(AnotherPojo.class);
// and so on ...
}}}

 * -Dprotostuff.runtime.morph_non_final_pojos=true
   * See [http://code.google.com/p/protostuff/issues/detail?id=43&can=1 this issue] for more details.
   * Basically, when your pojo's class is not declared final ... it can be subclassed (polymorphic)
   * Disabled by default.  Note that if you enable this option, every message will contain its type (w/c is a lot of overhead when your package names are long).
   

==Collection fields==

These field types are ignored:
 * {{{HashSet<List<Double>>}}} (collections with collection members)
 * {{{Queue<Map<String,Long>}}} (collections with map members)
 * {{{List<int[]>}}} (collections with array members)
   * Only the array {{{byte[]}}} is allowed (note that you should not rely on {{{List<byte[]>.equals()}}} for equality (you probably already know that about arrays)

{{{EnumSet}}} is not supported(in the future it can be).

==Map fields==

Same rules with collection fields for both keys and values.

{{{EnumMap}}} is not supported(in the future it can be).

====Polymorphism====
The values can be polymorphic.

The keys however cannot be (for performance reasons).  It is limited to:
 * scalar types (E.g {{{Map<String,Pojo>}}})
 * pojos (final class)

This should mostly cover 90% of all use-cases.

Having said that, the limitations for both {{{Collection}}} and {{{Map}}} fields are *soft limits*.  

Send a message to the discussion group if a limit is bugging you so we can discuss how to go about it.